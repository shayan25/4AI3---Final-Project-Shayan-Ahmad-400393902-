# -*- coding: utf-8 -*-
"""Copy_of_4AI3_Shayan_Ahmad_Noor_(400393902)_Project_(Generate_new_photograph).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ntq7SwHhoBM9_wvwi8hUmZZAiYFR2qfE

# **Project 4: Generate new photograph**

**Description:**

> Machine learning has covered almost all industries and it has helped humans
to mimic human-like behavior. Additionally, there are quite a few tasks where
ML algorithms are proven better than humans where humans have physical limi-
tations to achieve the task. One such interesting area is Image generation. A few
of the fields where image generation can be useful are redressing a person with a
given outfit or glasses, providing measurement of the cloth based on a photo of a
person, identifying the image of a person after 25 years, etc.


> The CIFAR-10 dataset (Canadian Institute for Advanced Research) is a collection
of images that are commonly used to train machine learning and computer vision
algorithms. It is one of the most widely used datasets for machine learning rese-
arch. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different
classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs,
frogs, horses, ships, and trucks. There are 6,000 images of each class.

> The scope of this project is to generate a new image that is not available in
real life, based on a model trained using the Generative Adversarial Model (GAN).

-------------------------

**Project Outcomes:**

> • Preprocess and clean the data.

> • Explore various options of GAN to find the most optimized model.

> • Generate a new image with a newly trained algorithm.

### **Imports:**
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout
from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import Model
from keras.utils import plot_model

# Load in the data
cifar10 = tf.keras.datasets.cifar10

# Distribute it to train and test set
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)

"""### **Data Visualization**"""

plt.imshow(x_train[0])

# Reduce pixel values
x_train, x_test = x_train / 255.0, x_test / 255.0

# flatten the label values
y_train, y_test = y_train.flatten(), y_test.flatten()

# Create a figure with a specified size to display multiple images.
plt.figure(figsize=(15,15))

# Loop through the first 25 images in the training dataset.
for i in range(25):
    # Arrange the images in a 5x5 grid.
    plt.subplot(5, 5, i + 1)
    # Remove x and y tick marks for a cleaner look.
    plt.xticks([])
    plt.yticks([])
    # Display each image.
    plt.imshow(x_train[i])
    # Label each image with its corresponding label from 'trainy'.
    plt.xlabel(y_train[i])

# Display the plotted figure with the images.
plt.show()

"""### **Define Discriminator, Generator, and combined GAN models**"""

from tensorflow.keras.layers import Reshape, Conv2DTranspose, LeakyReLU
from tensorflow.keras.models import Sequential

# Define the discriminator model
def define_discriminator(in_shape=(32,32,3)):
    model = Sequential()
    # Downsample
    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=in_shape))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.4))
    # Downsample
    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.4))
    # Classifier
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))
    # Compile model
    opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)
    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
    return model

# Define the generator model
def define_generator(latent_dim):
    model = Sequential()
    # Foundation for 8x8 image
    n_nodes = 128 * 8 * 8
    model.add(Dense(n_nodes, input_dim=latent_dim))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Reshape((8, 8, 128)))
    # Upsample to 16x16
    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))
    # Upsample to 32x32
    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))
    # Output layer
    model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))
    return model

# Define the combined GAN model
def define_gan(generator, discriminator):
    # Make the discriminator not trainable
    discriminator.trainable = False
    # Connect them
    model = Sequential()
    # Add generator
    model.add(generator)
    # Add the discriminator
    model.add(discriminator)
    # Compile model
    opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)
    model.compile(loss='binary_crossentropy', optimizer=opt)
    return model

# Size of the latent space
latent_dim = 100

# Create the discriminator
discriminator = define_discriminator()
discriminator.summary()

# Visualize the discriminator model's architecture, including layer shapes, names, and activations.
plot_model(discriminator, show_shapes=True, show_layer_names=True, show_layer_activations=True)

# Create the generator
generator = define_generator(latent_dim)
generator.summary()

# Visualize the structure of the generator model, displaying layer shapes, names, and activation functions.
plot_model(generator, show_shapes=True, show_layer_names=True, show_layer_activations=True)

# Create the GAN
gan = define_gan(generator, discriminator)
gan.summary()

# Visualize the GAN model's structure, showing layer shapes, names, and activation functions.
plot_model(gan, show_shapes=True, show_layer_names=True, show_layer_activations=True)

"""### **Train GAN**"""

# Import necessary libraries
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, Conv2DTranspose, LeakyReLU
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.models import load_model
from keras.models import load_model

# Load and preprocess the CIFAR-10 dataset
(x_train, _), (_, _) = cifar10.load_data()
x_train = x_train.astype('float32') / 255.0

# Constants
batch_size = 1000
n_epochs = 30
half_batch = int(batch_size / 2)
latent_dim = 100

# Define the generator, discriminator, and GAN models here (use the functions defined previously)

# Define function to generate real samples
def generate_real_samples(dataset, n_samples):
    ix = np.random.randint(0, dataset.shape[0], n_samples)
    X = dataset[ix]
    y = np.ones((n_samples, 1))
    return X, y

# Define function to generate fake samples
def generate_fake_samples(generator, latent_dim, n_samples):
    x_input = np.random.randn(latent_dim * n_samples)
    x_input = x_input.reshape(n_samples, latent_dim)
    X = generator.predict(x_input)
    y = np.zeros((n_samples, 1))
    return X, y

# Define save_plot function here
def save_plot(examples, epoch, n=10):
    # Creates a grid plot for the generated images
    plt.figure(figsize=(10, 10))
    for i in range(n * n):
        plt.subplot(n, n, 1 + i)
        plt.axis('off')
        plt.imshow(examples[i, :, :, :])
    # Construct the filename with the current epoch number.
    filename = 'generated_plot_e%03d.png' % (epoch+1)
    # Save the plot to a file.
    plt.savefig(filename)
    # Close the plot to free up memory.
    plt.close()

# Define evaluate function here
def evaluate(epoch, generator, discriminator, dataset, latent_dim, n_samples=100):
    # Evaluate the discriminator on real and fake samples
    X_real, y_real = generate_real_samples(dataset, n_samples)
    _, acc_real = discriminator.evaluate(X_real, y_real, verbose=0)

    X_fake, y_fake = generate_fake_samples(generator, latent_dim, n_samples)
    _, acc_fake = discriminator.evaluate(X_fake, y_fake, verbose=0)

    print(f'>Accuracy real: {acc_real*100:.0f}%, fake: {acc_fake*100:.0f}%')
    # Save generated images
    save_plot(X_fake, epoch)

    # Save the generator model
    filename = 'generator_model_%03d.h5' % (epoch + 1)
    generator.save(filename)

# Training loop
for i in range(n_epochs):
    for j in range(int(x_train.shape[0] / batch_size)):
        X_real, y_real = generate_real_samples(x_train, half_batch)
        X_fake, y_fake = generate_fake_samples(generator, latent_dim, half_batch)
        X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))
        d_loss, _ = discriminator.train_on_batch(X, y)

        X_gan = np.random.randn(latent_dim * batch_size)
        X_gan = X_gan.reshape(batch_size, latent_dim)
        y_gan = np.ones((batch_size, 1))
        g_loss = gan.train_on_batch(X_gan, y_gan)

        #print(f'>{i+1}, {j+1}/{int(x_train.shape[0] / batch_size)}, d={d_loss:.3f}, g={g_loss:.3f}')
        print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, int(x_train.shape[0] / batch_size), d_loss, g_loss))


    if (i+1) % 1 == 0:
        evaluate(i, generator, discriminator, x_train, latent_dim)

"""### **Evaluate Model: (Accuracy)**"""

def evaluate_on_test_set(generator, discriminator, test_dataset, latent_dim, n_samples=100):
    # Generate a batch of real samples from the test set
    X_real, y_real = generate_real_samples(test_dataset, n_samples)
    # Evaluate the discriminator on real samples
    _, acc_real = discriminator.evaluate(X_real, y_real, verbose=0)

    # Generate a batch of fake samples
    X_fake, y_fake = generate_fake_samples(generator, latent_dim, n_samples)
    # Evaluate the discriminator on fake samples
    _, acc_fake = discriminator.evaluate(X_fake, y_fake, verbose=0)

    # Print the accuracy
    print(f'Test Set Accuracy - Real: {acc_real*100:.0f}%, Fake: {acc_fake*100:.0f}%')

# Call this function to evaluate the model on the test set
evaluate_on_test_set(generator, discriminator, x_test, latent_dim)

"""### **Generate a New Image**"""

from tensorflow.keras.models import load_model
import numpy as np
import matplotlib.pyplot as plt
from keras.models import load_model

# Load the final trained generator model
# Replace 'final_model.h5' with the filename of your saved model
model = load_model('/content/generator_model_030.h5')

# Generate random input from the latent space
random_input = np.random.randn(100)  # 100 is the size of the latent dimension
random_input = random_input.reshape(1, 100)

# Use the generator to create an image
generated_image = model.predict(random_input)

# Display the generated image
plt.imshow(generated_image[0, :, :, :])
plt.axis('off')
plt.show()
